{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62716ba0-9f4a-48a1-81c3-cdbde8859f25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input video file path\n",
    "video_path = r\"D:\\Sem-4\\Project\\Datasets\\VISEM-Tracking - Datasets from Paper 2\\VISEM_Tracking_Train_v4\\Train\\11\\11.mp4\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit()\n",
    "\n",
    "# Background subtractor with adjusted parameters\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=25)\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Scaling factor to resize the video frames\n",
    "scale_factor = 0.5\n",
    "\n",
    "# Overlay text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org_text = (10, 30)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame\n",
    "    frame_resized = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Background Subtraction\n",
    "    foreground_mask = bg_subtractor.apply(frame_resized)\n",
    "\n",
    "    # 3. Noise Removal\n",
    "    # Morphological operations to clean the mask\n",
    "    foreground_mask_cleaned = cv2.morphologyEx(foreground_mask, cv2.MORPH_OPEN, kernel)\n",
    "    foreground_mask_cleaned = cv2.morphologyEx(foreground_mask_cleaned, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Smooth the mask using Gaussian blur\n",
    "    foreground_mask_blurred = cv2.GaussianBlur(foreground_mask_cleaned, (5, 5), 0)\n",
    "\n",
    "    # Apply thresholding to refine the mask\n",
    "    _, foreground_mask_final = cv2.threshold(foreground_mask_blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 4. Thresholding on grayscale image (unchanged)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 5. Morphological Operations (unchanged)\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)  # Opening\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # Closing\n",
    "\n",
    "    # 6. Edge Detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # 7. Blurring\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 8. Contour Detection\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_frame = frame_resized.copy()\n",
    "    cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Combine all images into a single visualization with labels\n",
    "    top_row = np.hstack([\n",
    "        cv2.putText(frame_resized.copy(), 'Original', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 'Grayscale', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(foreground_mask_final, cv2.COLOR_GRAY2BGR), 'Foreground', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    middle_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR), 'Threshold', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR), 'Opened', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR), 'Closed', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    bottom_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 'Edges', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR), 'Blurred', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(contour_frame, 'Contours', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "\n",
    "    # Stack the combined images\n",
    "    combined = np.vstack([top_row, middle_row, bottom_row])\n",
    "\n",
    "    # Display the combined visualization with file name and quit instructions\n",
    "    file_name = video_path.split(\"\\\\\")[-1]\n",
    "    cv2.putText(combined, f'File: {file_name}', (10, 50), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(combined, 'Press \"q\" to quit', (10, 80), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Classic Methods Visualization', combined)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Properly release the video and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560e2482-7879-4157-b824-1e1638d03c60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input video file path\n",
    "video_path = r\"D:\\Sem-4\\Project\\Datasets\\VISEM-Tracking - Datasets from Paper 2\\VISEM_Tracking_Train_v4\\Train\\11\\11.mp4\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit()\n",
    "\n",
    "# Background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Scaling factor to resize the video frames\n",
    "scale_factor = 0.5\n",
    "\n",
    "# Overlay text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org_text = (10, 30)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame\n",
    "    frame_resized = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Background Subtraction\n",
    "    foreground_mask = bg_subtractor.apply(frame_resized)\n",
    "\n",
    "    # 3. Thresholding\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 4. Morphological Operations\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)  # Opening\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # Closing\n",
    "\n",
    "    # 5. Edge Detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # 6. Blurring\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 7. Contour Detection\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_frame = frame_resized.copy()\n",
    "    cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Combine all images into a single visualization with labels\n",
    "    top_row = np.hstack([\n",
    "        cv2.putText(frame_resized.copy(), 'Original', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 'Grayscale', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(foreground_mask, cv2.COLOR_GRAY2BGR), 'Foreground', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    middle_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR), 'Threshold', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR), 'Opened', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR), 'Closed', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    bottom_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 'Edges', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR), 'Blurred', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(contour_frame, 'Contours', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "\n",
    "    # Stack the combined images\n",
    "    combined = np.vstack([top_row, middle_row, bottom_row])\n",
    "\n",
    "    # Display the combined visualization with file name and quit instructions\n",
    "    file_name = video_path.split(\"\\\\\")[-1]\n",
    "    cv2.putText(combined, f'File: {file_name}', (10, 50), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(combined, 'Press \"q\" to quit', (10, 80), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Classic Methods Visualization', combined)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Properly release the video and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5c3665-1cd8-4aea-8352-cc49df69a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Note: Removed imports for `torch` and `torch.nn` as they are not available in the current environment.\n",
    "\n",
    "# Input video file path\n",
    "video_path = r\"D:\\\\Sem-4\\\\Project\\\\Datasets\\\\VISEM-Tracking - Datasets from Paper 2\\\\VISEM_Tracking_Train_v4\\\\Train\\\\11\\\\11.mp4\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit(1)  # Provide an exit code\n",
    "\n",
    "# Background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Scaling factor to resize the video frames\n",
    "scale_factor = 0.5\n",
    "\n",
    "# Overlay text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org_text = (10, 30)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame\n",
    "    frame_resized = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Background Subtraction\n",
    "    foreground_mask = bg_subtractor.apply(frame_resized)\n",
    "\n",
    "    # 3. Thresholding\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 4. Morphological Operations\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)  # Opening\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # Closing\n",
    "\n",
    "    # 5. Edge Detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # 6. Blurring\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 7. Contour Detection\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_frame = frame_resized.copy()\n",
    "    cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Visualize contours with IDs (for debugging)\n",
    "    for idx, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.putText(contour_frame, f'ID: {idx}', (x, y - 10), font, 0.5, (255, 0, 0), 1)\n",
    "        cv2.rectangle(contour_frame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    # Combine all images into a single visualization\n",
    "    try:\n",
    "        top_row = np.hstack([\n",
    "            cv2.putText(frame_resized.copy(), 'Original', org_text, font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "            cv2.putText(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 'Grayscale', org_text, font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "            cv2.putText(cv2.cvtColor(foreground_mask, cv2.COLOR_GRAY2BGR), 'Foreground', org_text, font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        ])\n",
    "        bottom_row = np.hstack([\n",
    "            cv2.putText(contour_frame, 'Contours', org_text, font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "            cv2.putText(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 'Edges', org_text, font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "            cv2.putText(cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR), 'Blurred', org_text, font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        ])\n",
    "\n",
    "        # Stack the combined images\n",
    "        combined = np.vstack([top_row, bottom_row])\n",
    "\n",
    "        # Display the combined visualization\n",
    "        cv2.imshow('SPDConv Visualization', combined)\n",
    "\n",
    "    except cv2.error as e:\n",
    "        print(\"Error occurred while combining visualization: \", e)\n",
    "        break\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Properly release the video and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef940d-70a0-42d7-b65f-96d41d275104",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
