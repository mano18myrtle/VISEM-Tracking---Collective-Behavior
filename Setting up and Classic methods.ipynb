{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5adf4106-1b58-429a-b1f6-ad3f34e19233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asue\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\asue\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5546c-8805-4d67-abeb-6662fa76085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d20334-4f03-4b05-871e-ce4cd95c9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fccfc6-634d-4029-9acb-320f54b4a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3810c-dddd-439f-b094-5a2851d06ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4cc90-26e3-49c1-afdb-ab0c6473ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0497c65-6e50-4926-9ab7-b0ed860d0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2320c6e3-f253-4746-b4b7-23c22b074743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\asue\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\asue\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pandas in c:\\users\\asue\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asue\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy opencv-python pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4a5e5-fd66-44ec-89fa-7d7ea83e7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b563f9-3117-4f86-83ca-933b0a0b0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972f087b-71ad-462c-997e-4b5bd83b783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input video file path\n",
    "video_path = r\"D:\\\\Sem-4\\\\Project\\\\Datasets\\\\VISEM-Tracking - Datasets from Paper 2\\\\VISEM_Tracking_Train_v4\\\\Train\\\\11\\\\11.mp4\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit()\n",
    "\n",
    "# Background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Scaling factor to resize the video frames\n",
    "scale_factor = 0.5\n",
    "\n",
    "# Overlay text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org_text = (10, 30)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame\n",
    "    frame_resized = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Background Subtraction\n",
    "    foreground_mask = bg_subtractor.apply(frame_resized)\n",
    "\n",
    "    # 3. Thresholding\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 4. Morphological Operations\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)  # Opening\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # Closing\n",
    "\n",
    "    # 5. Edge Detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # 6. Blurring\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 7. Contour Detection\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_frame = frame_resized.copy()\n",
    "    cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Combine all images into a single visualization with labels\n",
    "    top_row = np.hstack([\n",
    "        cv2.putText(frame_resized.copy(), 'Original', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 'Grayscale', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(foreground_mask, cv2.COLOR_GRAY2BGR), 'Foreground', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    middle_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR), 'Threshold', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR), 'Opened', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR), 'Closed', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    bottom_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 'Edges', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR), 'Blurred', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(contour_frame, 'Contours', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "\n",
    "    # Stack the combined images\n",
    "    combined = np.vstack([top_row, middle_row, bottom_row])\n",
    "\n",
    "    # Display the combined visualization with file name and quit instructions\n",
    "    file_name = video_path.split(\"\\\\\")[-1]\n",
    "    cv2.putText(combined, f'File: {file_name}', (10, 50), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(combined, 'Press \"q\" to quit', (10, 80), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Classic Methods Visualization', combined)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Properly release the video and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d355bae3-7438-4adf-80e7-51c30f342390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asue\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a3038d-784a-4fe0-9c49-c4776f3d37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asue\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\asue\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\asue\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade opencv-python opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dce4a99-6bae-4162-9118-6ea33e9eaee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video.\n",
      "Processing complete. Saved to D:\\\\Sem-4\\\\Project\\\\Processed_Output.avi.\n"
     ]
    }
   ],
   "source": [
    "#To save the processed video\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input video file path\n",
    "video_path = r\"D:\\\\Sem-4\\\\Project\\\\Datasets\\\\VISEM-Tracking - Datasets from Paper 2\\\\VISEM_Tracking_Train_v4\\\\Train\\\\11\\\\11.mp4\"\n",
    "\n",
    "# Output video file path\n",
    "output_path = r\"D:\\\\Sem-4\\\\Project\\\\Processed_Output.avi\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for the output video\n",
    "\n",
    "# Scale down the resolution for processing\n",
    "scale_factor = 0.5\n",
    "output_width = int(frame_width * scale_factor)\n",
    "output_height = int(frame_height * scale_factor)\n",
    "\n",
    "# Initialize VideoWriter for saving the processed video\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (output_width * 3, output_height * 3))  # 3x3 grid\n",
    "\n",
    "# Background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Overlay text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame\n",
    "    frame_resized = cv2.resize(frame, (output_width, output_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Background Subtraction\n",
    "    foreground_mask = bg_subtractor.apply(frame_resized)\n",
    "\n",
    "    # 3. Thresholding\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 4. Morphological Operations\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)  # Opening\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # Closing\n",
    "\n",
    "    # 5. Edge Detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # 6. Blurring\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 7. Contour Detection\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_frame = frame_resized.copy()\n",
    "    cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Combine all images into a single visualization\n",
    "    top_row = np.hstack([\n",
    "        cv2.putText(frame_resized.copy(), 'Original', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 'Grayscale', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(foreground_mask, cv2.COLOR_GRAY2BGR), 'Foreground', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    middle_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR), 'Threshold', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR), 'Opened', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR), 'Closed', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    bottom_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 'Edges', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR), 'Blurred', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(contour_frame, 'Contours', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "\n",
    "    # Stack the combined images\n",
    "    combined = np.vstack([top_row, middle_row, bottom_row])\n",
    "\n",
    "    # Write to the output video\n",
    "    out.write(combined)\n",
    "\n",
    "# Properly release the video and writer\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Processing complete. Saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d09071-4924-4893-9970-7bead11a35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input video file path\n",
    "video_path = r\"D:\\\\Sem-4\\\\Project\\\\Datasets\\\\VISEM-Tracking - Datasets from Paper 2\\\\VISEM_Tracking_Train_v4\\\\Train\\\\11\\\\11.mp4\"\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video.\")\n",
    "    exit()\n",
    "\n",
    "# Scaling factor to resize the video frames\n",
    "scale_factor = 0.5\n",
    "\n",
    "# Background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Kernel for morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Overlay text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame\n",
    "    frame_resized = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Background Subtraction\n",
    "    foreground_mask = bg_subtractor.apply(frame_resized)\n",
    "\n",
    "    # 3. Thresholding\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 4. Morphological Operations\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)  # Opening\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # Closing\n",
    "\n",
    "    # 5. Edge Detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # 6. Blurring\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 7. Contour Detection\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_frame = frame_resized.copy()\n",
    "    cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Combine all images into a single visualization\n",
    "    top_row = np.hstack([\n",
    "        cv2.putText(frame_resized.copy(), 'Original', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 'Grayscale', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(foreground_mask, cv2.COLOR_GRAY2BGR), 'Foreground', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    middle_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR), 'Threshold', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR), 'Opened', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(closed, cv2.COLOR_GRAY2BGR), 'Closed', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "    bottom_row = np.hstack([\n",
    "        cv2.putText(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), 'Edges', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR), 'Blurred', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA),\n",
    "        cv2.putText(contour_frame, 'Contours', (10, 30), font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    ])\n",
    "\n",
    "    # Stack the combined images\n",
    "    combined = np.vstack([top_row, middle_row, bottom_row])\n",
    "\n",
    "    # Display the combined visualization\n",
    "    cv2.imshow('Classic Methods Visualization', combined)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Properly release the video and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
